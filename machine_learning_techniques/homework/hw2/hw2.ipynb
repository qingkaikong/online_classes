{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn import linear_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Question 7"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#just do a simulation\n",
      "x_ = []\n",
      "y_ = []\n",
      "n = 1000\n",
      "for i in range(n):\n",
      "    x = np.random.uniform()\n",
      "    x_.append(x)\n",
      "    y_.append(x**2)\n",
      "    \n",
      "\n",
      "X = np.array(x_).reshape(n, 1)\n",
      "y = np.array(y_).reshape(n, 1)\n",
      "\n",
      "regr = linear_model.LinearRegression()\n",
      "\n",
      "# Train the model \n",
      "regr.fit(X, y)\n",
      "print regr.coef_\n",
      "print regr.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.99905772]]\n",
        "[-0.16598899]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Question 12 - 18"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#question 12\n",
      "data_train = np.loadtxt('../../data/hw2/hw2_adaboost_train.dat')\n",
      "X_train = data_train[:, :2]\n",
      "y_train = data_train[:,-1]\n",
      "\n",
      "data_test = np.loadtxt('../../data/hw2/hw2_adaboost_test.dat')\n",
      "X_test = data_test[:, :2]\n",
      "y_test = data_test[:,-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stumpClassify(dataMat, dimen, threshVal, ineq):\n",
      "    retArr = np.ones((dataMat.shape[0], 1))\n",
      "    if ineq == 'lt':\n",
      "        retArr[dataMat[:, dimen] <= threshVal] = -1.0\n",
      "    else:\n",
      "        retArr[dataMat[:, dimen] > threshVal] = -1.0\n",
      "    return retArr\n",
      "\n",
      "def buildStump(dataArr_sorted, classLabels, u):\n",
      "    '''\n",
      "    function to build the decision stump\n",
      "    \n",
      "    Input: \n",
      "    dataArr - numpy arrary contains features should be (N, m) array\n",
      "    classLabels - numpy array contains features should be (N, 1) array\n",
      "    u - numpy arrary contains weights for the input data, should be (N, 1)\n",
      "    \n",
      "    '''\n",
      "    \n",
      "    dataMat = np.mat(dataArr_sorted)\n",
      "    labelMat = np.mat(classLabels.T)\n",
      "    N, m = dataMat.shape\n",
      "    bestStump = {} \n",
      "    bestClassEst = np.mat(np.zeros((N, 1)))\n",
      "    minError = np.inf\n",
      "    dataMat_avg = np.insert(movingaverage(dataMat,2), 0, -np.inf)\n",
      "    \n",
      "    for i in range(N):\n",
      "        for j in range(len(dataMat_avg)):\n",
      "            for inequal in ['lt', 'gt']:\n",
      "                threshVal = dataMat_avg[j]\n",
      "                predicatedVal = stumpClassify(dataMat, i, threshVal, inequal)\n",
      "                errArr = np.mat(np.ones((N, 1)))\n",
      "                #for the row that predicatedVal == labelMat, errArr[row] = 0\n",
      "                errArr[predicatedVal == labelMat] = 0\n",
      "                weightedError = u.T * errArr\n",
      "                #print 'split: dim %d, thesh %.2f, ineqal: %s, \\\n",
      "                #weighted error:%.3f' %(i,threshVal,inequal,weightedError)\n",
      "                if weightedError < minError:\n",
      "                    minError = weightedError\n",
      "                    bestClassEst = predicatedVal.copy()\n",
      "                    bestStump['dim'] = i\n",
      "                    bestStump['thresh'] = threshVal\n",
      "                    bestStump['ineq'] = inequal\n",
      "                    \n",
      "    return bestStump, minError, bestClassEst "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def adaBoost(dataArr, classLabels, numIter = 40):\n",
      "    '''\n",
      "    Input: \n",
      "    dataArr - numpy arrary contains features should be (N, m) array\n",
      "    classLabels - numpy array contains features should be (N,1) array\n",
      "    numIter - number of iterations\n",
      "    '''\n",
      "    bestStumpArr = []\n",
      "    #get how many data points we have\n",
      "    N = dataArr.shape[0]\n",
      "    #initial the weights matrix u with 1/N\n",
      "    u = np.mat(np.ones((N,1))/N)\n",
      "    aggClassEst = np.mat(np.zeros((N,1)))\n",
      "    \n",
      "    for i in range(numIter):\n",
      "        bestStump, error, bestClassEst = buildStump(dataArr, classLabels, D)\n",
      "        \n",
      "        \n",
      "        print 'u:', u.T\n",
      "        alpha = float(0.5 * log((1.0 - error)/max(error, 1e-16)))\n",
      "        bestStump['alpha'] = alpha\n",
      "        bestStumpArr.append(bestStump)\n",
      "        print 'ClassEst:', bestClassEst.T\n",
      "        \n",
      "        #multiply(): element-wise product. class real result X estimation\n",
      "        expon = np.multiply(-1 * alpha * np.mat(classLabels).T, bestClassEst)\n",
      "        #exp(expon): calculate exp for each element in mat expon\n",
      "        u = np.multiply(u, np.exp(expon)) / sum(u)\n",
      "        \n",
      "        #aggClassEst is float mat.\n",
      "        aggClassEst += alpha * bestClassEst\n",
      "        print 'aggClassEst:', aggClassEst\n",
      "        \n",
      "        #aggClassEst is float mat, use its sign to compare with mat classLabels\n",
      "        aggError = np.multiply(sign(aggClassEst) != np.mat(classLabels).T, ones((N,1)))\n",
      "        errorRate = np.sum(aggError)/N\n",
      "        print 'total error:', errorRate\n",
      "        \n",
      "        if errorRate == 0.0:\n",
      "            break\n",
      "        \n",
      "    return bestStumpArr\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adaBoost(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 1)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def movingaverage(values,window):\n",
      "    weigths = np.repeat(1.0, window)/window\n",
      "    #including valid will REQUIRE there to be enough datapoints.\n",
      "    #for example, if you take out valid, it will start @ point one,\n",
      "    #not having any prior points, so itll be 1+0+0 = 1 /3 = .3333\n",
      "    smas = np.convolve(values, weigths, 'valid')\n",
      "    return smas # as a numpy array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.array([1, 2, 3, 4, 5, 6, 7])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.insert(movingaverage(a,2), 0, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "array([ 1. ,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(7,)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.matrix(a).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(1, 7)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
      "                         algorithm=\"SAMME\",\n",
      "                         n_estimators=400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bdt.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "AdaBoostClassifier(algorithm='SAMME',\n",
        "          base_estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=1, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best'),\n",
        "          learning_rate=1.0, n_estimators=400, random_state=None)"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bdt.score(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bdt.estimator_weights_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([ 1.09861229,  1.56218503,  1.16763421,  1.14151867,  0.73424284,\n",
        "        0.99671783,  0.67823407,  0.31926735,  0.51645788,  0.61915898,\n",
        "        0.47007175,  0.25343686,  0.32415781,  0.45220084,  0.36786674,\n",
        "        0.46296977,  0.41218324,  0.47055763,  0.3798484 ,  0.49777461,\n",
        "        0.62883491,  0.2255695 ,  0.54198891,  0.22760821,  0.25270987,\n",
        "        0.22424177,  0.20155769,  0.18727324,  0.27857469,  0.50856844,\n",
        "        0.2859232 ,  0.15424401,  0.17199366,  0.36917977,  0.31118598,\n",
        "        0.38337413,  0.5625366 ,  0.36812005,  0.18620889,  0.16759623,\n",
        "        0.15461203,  0.14349823,  0.13387726,  0.14364372,  0.33914619,\n",
        "        0.31786664,  0.36724465,  0.29869644,  0.38930299,  0.35000268,\n",
        "        0.49029455,  0.29995361,  0.32396681,  0.23837743,  0.32887172,\n",
        "        0.31964459,  0.31015142,  0.47378122,  0.52227411,  0.11538505,\n",
        "        0.19700464,  0.45552627,  0.2592491 ,  0.3210804 ,  0.48936335,\n",
        "        0.26080627,  0.23859018,  0.28498468,  0.16133871,  0.14927279,\n",
        "        0.13888871,  0.30254969,  0.26256637,  0.38639448,  0.42910702,\n",
        "        0.24308904,  0.50589482,  0.39035766,  0.18217976,  0.13225354,\n",
        "        0.31512629,  0.27196734,  0.29522435,  0.4183898 ,  0.53939009,\n",
        "        0.3448774 ,  0.30835797,  0.21680772,  0.3077866 ,  0.26649389,\n",
        "        0.28307081,  0.38306233,  0.31912178,  0.26755277,  0.37943985,\n",
        "        0.44950533,  0.16381891,  0.22548798,  0.28222054,  0.54287344,\n",
        "        0.40187275,  0.14846949,  0.12744378,  0.11980017,  0.12349937,\n",
        "        0.31039623,  0.26844413,  0.11933772,  0.15202055,  0.36279052,\n",
        "        0.30664839,  0.35482344,  0.42971263,  0.28035427,  0.24214491,\n",
        "        0.22642501,  0.31915882,  0.31726688,  0.31877423,  0.44690214,\n",
        "        0.38179012,  0.35120634,  0.2988385 ,  0.36383156,  0.31397358,\n",
        "        0.15477543,  0.34071573,  0.29077042,  0.25366417,  0.27202918,\n",
        "        0.23930347,  0.09582523,  0.11579426,  0.29733596,  0.30430683,\n",
        "        0.37991576,  0.3187527 ,  0.31222605,  0.45300495,  0.26568454,\n",
        "        0.34502626,  0.26913261,  0.12210313,  0.11506971,  0.18334516,\n",
        "        0.38986078,  0.2199522 ,  0.27031759,  0.42187402,  0.47609378,\n",
        "        0.22425079,  0.36152692,  0.19060477,  0.10196482,  0.10041457,\n",
        "        0.2870964 ,  0.28207949,  0.32094381,  0.4194042 ,  0.40193197,\n",
        "        0.26936112,  0.33109493,  0.28089937,  0.24613075,  0.20724965,\n",
        "        0.38769976,  0.2082839 ,  0.10351662,  0.11036687,  0.29520882,\n",
        "        0.28139083,  0.36797194,  0.20969789,  0.39831069,  0.32053532,\n",
        "        0.3305026 ,  0.45210445,  0.27139932,  0.35921204,  0.33859899,\n",
        "        0.25099496,  0.18568371,  0.09748035,  0.11150007,  0.10560671,\n",
        "        0.10030556,  0.25959128,  0.26529006,  0.30744329,  0.40262436,\n",
        "        0.49500748,  0.39551   ,  0.27308011,  0.41295006,  0.3348917 ,\n",
        "        0.31866862,  0.49076306,  0.33958153,  0.21383437,  0.126071  ,\n",
        "        0.11858652,  0.11194178,  0.28835709,  0.29050126,  0.22741042,\n",
        "        0.18230818,  0.25769984,  0.23390289,  0.28403749,  0.39107476,\n",
        "        0.40643324,  0.39878132,  0.37517552,  0.32888089,  0.40025167,\n",
        "        0.33288904,  0.2690785 ,  0.22349761,  0.20095676,  0.28060293,\n",
        "        0.24825979,  0.19160429,  0.17481029,  0.24438019,  0.27023462,\n",
        "        0.32382789,  0.40556854,  0.3934707 ,  0.37327013,  0.3646165 ,\n",
        "        0.30960412,  0.25801628,  0.22681395,  0.35998299,  0.24680817,\n",
        "        0.29499552,  0.21702054,  0.29220546,  0.28509984,  0.2601574 ,\n",
        "        0.3242212 ,  0.49437983,  0.27498363,  0.28144127,  0.23849309,\n",
        "        0.2915639 ,  0.37999327,  0.31880706,  0.39891796,  0.3967336 ,\n",
        "        0.172377  ,  0.33674315,  0.32060122,  0.30867378,  0.35014267,\n",
        "        0.4436415 ,  0.30951356,  0.38357235,  0.27717067,  0.34287343,\n",
        "        0.24303158,  0.30615419,  0.27448166,  0.12788638,  0.12019113,\n",
        "        0.11337034,  0.10735867,  0.10188458,  0.10787285,  0.10234751,\n",
        "        0.13873871,  0.28011975,  0.2151645 ,  0.09549466,  0.09828791,\n",
        "        0.26011672,  0.23004761,  0.28821724,  0.20370565,  0.37461056,\n",
        "        0.18239279,  0.35136294,  0.27664409,  0.22102772,  0.29438494,\n",
        "        0.39870466,  0.2575707 ,  0.29812872,  0.30085396,  0.2942691 ,\n",
        "        0.35050238,  0.42086723,  0.32070391,  0.35438908,  0.39899996,\n",
        "        0.33202627,  0.41008463,  0.38064187,  0.19613958,  0.31452933,\n",
        "        0.23425442,  0.32815029,  0.32471781,  0.3212358 ,  0.16106858,\n",
        "        0.25027475,  0.23542968,  0.10358998,  0.09848464,  0.28156789,\n",
        "        0.42560894,  0.234249  ,  0.26871748,  0.31327586,  0.30672271,\n",
        "        0.34134987,  0.38376575,  0.22674763,  0.09710038,  0.14930211,\n",
        "        0.34820211,  0.29619036,  0.29487053,  0.37703627,  0.31679867,\n",
        "        0.23213735,  0.10230247,  0.09835612,  0.2537357 ,  0.26709313,\n",
        "        0.12371408,  0.09869828,  0.25835311,  0.4090681 ,  0.38117981,\n",
        "        0.22949216,  0.35603411,  0.23725526,  0.0926204 ,  0.10611657,\n",
        "        0.19068121,  0.174042  ,  0.28414624,  0.2840937 ,  0.28985353,\n",
        "        0.36639101,  0.3092086 ,  0.42726161,  0.28130328,  0.29292651,\n",
        "        0.0856384 ,  0.15141494,  0.31806821,  0.24367299,  0.26045919,\n",
        "        0.21267592,  0.08865813,  0.10150166,  0.29057479,  0.41923133,\n",
        "        0.3607219 ,  0.37958468,  0.34569664,  0.38258005,  0.32061932,\n",
        "        0.31731278,  0.2406538 ,  0.09872945,  0.1524562 ,  0.22003901,\n",
        "        0.1665324 ,  0.08472156,  0.09483177,  0.25685312,  0.22749427,\n",
        "        0.09323113,  0.08907593,  0.26367687,  0.26990847,  0.26140408,\n",
        "        0.39303212,  0.31449113,  0.36414828,  0.41804048,  0.36650932,\n",
        "        0.40367657,  0.22637171,  0.19742962,  0.17964366,  0.08417813,\n",
        "        0.09157187,  0.24493213,  0.21810282,  0.27339487,  0.41648436,\n",
        "        0.28283998,  0.32391412,  0.35935784,  0.20849546,  0.19242669])"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-np.inf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "-inf"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}